{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLDaTo\n",
    "\n",
    "> MLDaTo (Machine Learning on Data auTomated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ryanf\\\\Google Drive\\\\Projects\\\\Personal\\\\mldato'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#server\n",
    "df=pd.read_csv('.\\\\data\\\\train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis\n",
    "\n",
    "* Depends: pandas, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def explore_df(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    A more advanced version of describe for tabular exploratory data analysis. Inlcudes additional information such as,\n",
    "    missing observations, unique observations, constant feature flagging, all_missing feature flagging, feature types & outlier\n",
    "    values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas df, required, default=NA\n",
    "        Pandas dataframe object \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas df\n",
    "        Returns a pandas dataframe object\n",
    "    \n",
    "    Usage\n",
    "    -----\n",
    "        df = pd.DataFrame({\"x1\": [\"a\", \"b\", \"c\", \"a\"], \"x2\":['x','y','x','x'], \"y\": [1,1,0,1]})\n",
    "        eda = explore_df(df=df)\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    ft = pd.DataFrame()\n",
    "    ft['type']=df.dtypes.astype(str)\n",
    "    ft['feature']=ft.index\n",
    "    ft['unique']=df.nunique()\n",
    "    ft['missing']= df.isnull().sum()\n",
    "    ft['constant']=np.where(ft['unique']==1,1,0)\n",
    "    ft['all_missing']=np.where(ft['missing']==df.shape[0],1,0)\n",
    "\n",
    "    numeric = ft.loc[(ft['type'].str.contains('float'))]['feature']\n",
    "    numeric = numeric.append(ft.loc[(ft['type'].str.contains('int'))]['feature'])\n",
    "    \n",
    "    categorical = ft.loc[(ft['type'].str.contains('object'))]['feature']\n",
    "\n",
    "    # Summary statistics\n",
    "    lower=df[numeric].quantile(q=0.25)\n",
    "    upper=df[numeric].quantile(q=0.75)\n",
    "    ft['min']=df[numeric].min()\n",
    "    ft['q1']=lower\n",
    "    ft['median']=df[numeric].median()\n",
    "    ft['mean']=df[numeric].mean()\n",
    "    ft['q3']=upper\n",
    "    ft['max']=df[numeric].max()\n",
    "\n",
    "    # Caclulate outlier values\n",
    "    iqr = upper - lower\n",
    "    lower=lower-(1.5*iqr)\n",
    "    upper=upper+(1.5*iqr)\n",
    "    ft['lower_outlier']=lower\n",
    "    ft['upper_outlier']=upper\n",
    "    ft['skewness']=df[numeric].skew()\n",
    "    \n",
    "    ft['class'] = np.where(ft['type'].str.contains('float'), 'numeric', None)\n",
    "    ft['class'] = np.where(ft['type'].str.contains('int'), 'numeric', ft['class'])\n",
    "    ft['class'] = np.where(ft['type'].str.contains('object'), 'categorical', ft['class'])\n",
    "    ft['class'] = np.where(ft['type'].str.contains('datetime'), 'datetime', ft['class'])\n",
    "    ft['class'] = np.where(ft['class'].isin(['numeric','integer']) & \n",
    "                           (ft['min'] == 0) & \n",
    "                           (ft['max'] == 1) & \n",
    "                           (ft['unique'] == 2), 'indicator', ft['class'])\n",
    "        \n",
    "    ft=ft[['feature','type','class','missing','unique','constant','all_missing','min','q1','median',\n",
    "         'mean','q3','max','lower_outlier','upper_outlier','skewness']]\n",
    "\n",
    "    ft=ft.reset_index(drop=True)\n",
    "    return ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#server\n",
    "eda = explore_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format features\n",
    "\n",
    "* Depends: numpy, pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def format_features(df):\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    \"\"\"\n",
    "    Applies feature formatting to features to comply with machine learning models. Boolean features are transformed to integer \n",
    "    and objects (where applicable) are tried to be formatted as datetime. The resulting feature set should only contain float,\n",
    "    integer, object and datetime type features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas df, required, default=NA\n",
    "        Pandas dataframe object \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas df\n",
    "        Returns a pandas dataframe object\n",
    "    \n",
    "    Usage\n",
    "    -----\n",
    "        df = pd.DataFrame({\"x1\": [\"a\", \"b\", \"c\", \"a\"], \"x2\":['x','y','x','x'], \"y\": [1,1,0,1]})\n",
    "        df = format_features(df=df)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Try and convert relevant datetime columns to datetime format\n",
    "    df = df.apply(lambda col: pd.to_datetime(col, errors='ignore') \n",
    "              if col.dtypes == object \n",
    "              else col, \n",
    "              axis=0)\n",
    "\n",
    "    ft = pd.DataFrame()\n",
    "    ft['from_type'] = df.dtypes.astype(str)\n",
    "    ft['feature'] = ft.index\n",
    "    logical = ft.loc[ft['from_type'] == 'bool']['feature'].unique()\n",
    "    df[logical] = df[logical].astype(int) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#server\n",
    "df = format_features(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect features\n",
    "\n",
    "* TODO: Add in functionality to detect flag features, having nr of uniques = 2 and set values\n",
    "* Depends: numpy, pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def detect_features(df, y = None, id = None):\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    \"\"\"\n",
    "    Detects features of different types and returns each type in individual series objects. Feature types detected and grouped are\n",
    "    numeric (float and integer), categorical (object and category), datetime (date) and flags (unique of 2 containing special\n",
    "    values).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas df, required, default=NA\n",
    "        Pandas dataframe object \n",
    "    y: str, optional, default=None\n",
    "        Name of the target feature\n",
    "    id: str, optional, default=None\n",
    "        Name of the id feature\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas series\n",
    "        Returns a series for numeric, categorical, datetime and flag features in that order\n",
    "    \n",
    "    Usage\n",
    "    -----\n",
    "        df = pd.DataFrame({\"x1\": [\"a\", \"b\", \"c\", \"a\"], \"x2\":['x','y','x','x'], \"y\": [1,1,0,1]})\n",
    "        numeric, categorical, datetime, flag = detect_features(df)\n",
    "    \"\"\"\n",
    "\n",
    "    ft = pd.DataFrame()\n",
    "    ft['type'] = df.dtypes.astype(str)\n",
    "    ft['feature']=ft.index\n",
    "    ft['unique']=df.nunique()\n",
    "    ft.reset_index(drop=True, inplace=True)\n",
    "    numeric = ft.loc[(ft['type'].str.contains('float'))]['feature']\n",
    "    numeric = numeric.append(ft.loc[(ft['type'].str.contains('int'))]['feature'])\n",
    "\n",
    "    categorical = ft.loc[(ft['type'].str.contains('object'))]['feature']\n",
    "    categorical = categorical.append(ft.loc[(ft['type'].str.contains('category'))]['feature'])\n",
    "\n",
    "    datetime = ft.loc[(ft['type'].str.contains('date'))]['feature']\n",
    "\n",
    "    if y is not None:\n",
    "        numeric = numeric.loc[numeric != y]\n",
    "        categorical = categorical.loc[categorical != y]\n",
    "\n",
    "    if id is not None:\n",
    "        numeric = numeric.loc[numeric != id]\n",
    "        categorical = categorical.loc[categorical != id]\n",
    "\n",
    "    return numeric, categorical, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#server\n",
    "numeric, categorical, datetime = detect_features(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parition data\n",
    "\n",
    "Parition data into a train, validation and test set either by stratified random sampling or time sensitive partitioning. For time sensitive partitioning, the data is sorted by the time dependent feature and then split according to percentages of the data running acrros time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#server\n",
    "y = 'Survived'\n",
    "x = ['Sex',\n",
    "       'Age', 'SibSp']\n",
    "test_percentage = 0.2\n",
    "valid_percentage = 0.1\n",
    "time_based_split_feature = None\n",
    "seed = 1234\n",
    "max_uniques = 100\n",
    "\n",
    "n_test = df.shape[0] * test_percentage\n",
    "n_valid = df.shape[0] * valid_percentage\n",
    "\n",
    "if time_based_split_feature is not None:\n",
    "    df = df.sort_values(time_based_split_feature)\n",
    "    test = df.tail(round(n_test))\n",
    "    \n",
    "    train = df.iloc[ : df.shape[0] - round(n_test)]\n",
    "    valid = train.tail(round(n_valid))\n",
    "    \n",
    "    train = train.iloc[ : train.shape[0] - round(n_valid)]\n",
    "\n",
    "if y is not None:\n",
    "    \n",
    "    # Classification outcome\n",
    "    if df[y].nunique() <= max_uniques:\n",
    "        \n",
    "        df[y] = df[y].astype('category').cat.codes # Transform target feature\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(df[x], df[y], stratify=df[y], \n",
    "                                                        test_size=test_percentage, random_state=seed)\n",
    "        \n",
    "        train = x_train.copy()\n",
    "        train[y] = y_train\n",
    "        \n",
    "        test = x_test.copy()\n",
    "        test[y] = y_test\n",
    "        \n",
    "        # Caluclate new validation split   \n",
    "        valid_percentage = n_valid / x_train.shape[0]\n",
    "\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(train[x], train[y], stratify=train[y], \n",
    "                                                            test_size=valid_percentage, random_state=seed)\n",
    "\n",
    "        train = x_train.copy()\n",
    "        train[y] = y_train\n",
    "\n",
    "        valid = x_valid.copy()\n",
    "        valid[y] = y_valid\n",
    "    \n",
    "    # Regression\n",
    "    if df[y].nunique() > max_uniques:\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(df[x], df[y], test_size=test_percentage, random_state=seed)\n",
    "        \n",
    "        train = x_train.copy()\n",
    "        train[y] = y_train\n",
    "        \n",
    "        test = x_test.copy()\n",
    "        test[y] = y_test\n",
    "        \n",
    "        # Caluclate new validation split   \n",
    "        valid_percentage = n_valid / x_train.shape[0]\n",
    "\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(train[x], train[y], test_size=valid_percentage, random_state=seed)\n",
    "\n",
    "        train = x_train.copy()\n",
    "        train[y] = y_train\n",
    "\n",
    "        valid = x_valid.copy()\n",
    "        valid[y] = y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_timeseries.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
